# ä» Gaussian Splatting æ¸²æŸ“åˆ° SDF Studio çš„å®Œæ•´æµç¨‹

## ğŸ“‹ ä½ çš„ç›®æ ‡

```
å·²è®­ç»ƒçš„ GS æ¨¡å‹ 
    â†“
ç”Ÿæˆç¯ç»•ç‰©ä½“çš„å¤šè§†è§’æ¸²æŸ“å›¾åƒï¼ˆRGB + Depth + Normalï¼‰
    â†“
è½¬æ¢ä¸º SDF Studio å¯ç”¨çš„æ•°æ®æ ¼å¼
    â†“
è®­ç»ƒ SDF / Neural Surface æ¨¡å‹
```

## ğŸ” æ ¸å¿ƒé—®é¢˜è§£æ

### é—®é¢˜ 1: render.py èƒ½åšä»€ä¹ˆï¼Ÿ

**ç­”æ¡ˆï¼šå¯ä»¥ï¼Œä½†æœ‰é™åˆ¶**

è¿™ä¸ª `render.py` è„šæœ¬çš„åŠŸèƒ½ï¼š
```python
# å®ƒåšçš„äº‹æƒ…ï¼š
1. åŠ è½½å·²è®­ç»ƒçš„ GS æ¨¡å‹
2. ä½¿ç”¨è®­ç»ƒ/æµ‹è¯•é›†ä¸­çš„ç›¸æœºä½å§¿æ¸²æŸ“å›¾åƒ
3. è¾“å‡ºï¼šRGBã€Depthã€Normal

# é™åˆ¶ï¼š
- åªèƒ½æ¸²æŸ“è®­ç»ƒ/æµ‹è¯•é›†ä¸­å·²æœ‰çš„ç›¸æœºè§†è§’
- ä¸èƒ½è‡ªå®šä¹‰æ–°çš„ç›¸æœºè½¨è¿¹
```

ä»£ç åˆ†æï¼š
```python
# render.py ç¬¬ 194 è¡Œ
if not skip_train:
    render_set(..., scene.getTrainCameras(), ...)  # åªç”¨è®­ç»ƒé›†çš„ç›¸æœº

if not skip_test:
    render_set(..., scene.getTestCameras(), ...)   # åªç”¨æµ‹è¯•é›†çš„ç›¸æœº
```

### é—®é¢˜ 2: transforms.json ä¸­çš„ pose æ˜¯ä»€ä¹ˆåæ ‡ç³»ï¼Ÿ

**transforms.json çš„ç»“æ„ï¼š**
```json
{
    "camera_angle_x": 0.8575560450553894,
    "frames": [
        {
            "file_path": "./images/frame_00001.jpg",
            "transform_matrix": [
                [0.9999, 0.0000, 0.0087, 0.0352],
                [0.0000, 1.0000, 0.0000, 0.0000],
                [-0.0087, 0.0000, 0.9999, 3.5825],
                [0.0, 0.0, 0.0, 1.0]
            ]
        }
    ]
}
```

**åæ ‡ç³»å®šä¹‰ï¼š**
```
transform_matrix æ˜¯ 4x4 çš„ camera-to-world å˜æ¢çŸ©é˜µï¼š

C2W = [R | t]  =  [r11 r12 r13 tx]
      [0 | 1]     [r21 r22 r23 ty]
                  [r31 r32 r33 tz]
                  [0   0   0   1 ]

å…¶ä¸­ï¼š
- R (3x3): æ—‹è½¬çŸ©é˜µï¼Œæè¿°ç›¸æœºæœå‘
- t (3x1): å¹³ç§»å‘é‡ï¼Œæè¿°ç›¸æœºåœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®
```

**NeRF/Nerfstudio åæ ‡ç³»çº¦å®šï¼š**
```
+Y
 â†‘   
 |  +Z (ç›¸æœºæœå‘åœºæ™¯å†…éƒ¨)
 | â†—
 |/
 +-------â†’ +X

- X: å³
- Y: ä¸Š  
- Z: å‰ï¼ˆç›¸æœºçœ‹å‘çš„æ–¹å‘ï¼‰
```

**å…³é”®ç‚¹ï¼š**
- æ‰€æœ‰ç›¸æœº pose éƒ½åœ¨åŒä¸€ä¸ªä¸–ç•Œåæ ‡ç³»ä¸­
- è¿™ä¸ªä¸–ç•Œåæ ‡ç³»çš„åŸç‚¹å’Œæœå‘æ˜¯ COLMAP é‡å»ºæ—¶è‡ªåŠ¨ç¡®å®šçš„
- é€šå¸¸åŸç‚¹åœ¨åœºæ™¯çš„æŸä¸ªä¸­å¿ƒä½ç½®é™„è¿‘

### é—®é¢˜ 3: å¦‚ä½•ç”Ÿæˆç¯ç»•ç‰©ä½“çš„ç›¸æœºè½¨è¿¹ï¼Ÿ

ä½ éœ€è¦**è‡ªå·±ç”Ÿæˆä¸€ç³»åˆ—ç›¸æœº pose**ï¼Œè®©å®ƒä»¬ç¯ç»•ä½ æ„Ÿå…´è¶£çš„ç‰©ä½“ã€‚

## ğŸ¯ å®Œæ•´è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆæ¶æ„

```
æ­¥éª¤ 1: ç¡®å®šç›®æ ‡ç‰©ä½“åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®
æ­¥éª¤ 2: ç”Ÿæˆç¯ç»•ç‰©ä½“çš„ç›¸æœºè½¨è¿¹ï¼ˆè‡ªå®šä¹‰ posesï¼‰
æ­¥éª¤ 3: ä¿®æ”¹ render.py ä»¥ä½¿ç”¨è‡ªå®šä¹‰è½¨è¿¹
æ­¥éª¤ 4: æ¸²æŸ“ RGB + Depth + Normal
æ­¥éª¤ 5: è½¬æ¢ä¸º SDF Studio æ ¼å¼
```

### æ­¥éª¤ 1: ç¡®å®šç›®æ ‡ç‰©ä½“ä½ç½®

**æ–¹æ³• A: ä»è®­ç»ƒæ•°æ®åˆ†æï¼ˆæ¨èï¼‰**

```python
import json
import numpy as np

# è¯»å– transforms.json
with open('transforms.json', 'r') as f:
    data = json.load(f)

# æå–æ‰€æœ‰ç›¸æœºä½ç½®
camera_positions = []
for frame in data['frames']:
    T = np.array(frame['transform_matrix'])
    camera_pos = T[:3, 3]  # ç›¸æœºä½ç½® (x, y, z)
    camera_positions.append(camera_pos)

camera_positions = np.array(camera_positions)

# ç‰©ä½“å¤§æ¦‚åœ¨ç›¸æœºæ³¨è§†çš„ä¸­å¿ƒ
object_center = camera_positions.mean(axis=0)
print(f"ä¼°è®¡çš„ç‰©ä½“ä¸­å¿ƒ: {object_center}")

# è®¡ç®—ç›¸æœºåˆ°ä¸­å¿ƒçš„å¹³å‡è·ç¦»ï¼ˆç”¨äºç¡®å®šè½¨è¿¹åŠå¾„ï¼‰
distances = np.linalg.norm(camera_positions - object_center, axis=1)
avg_radius = distances.mean()
print(f"å¹³å‡ç›¸æœºè·ç¦»: {avg_radius}")
```

**æ–¹æ³• B: æ‰‹åŠ¨æŒ‡å®šï¼ˆå¦‚æœä½ çŸ¥é“ç‰©ä½“ä½ç½®ï¼‰**

```python
# å‡è®¾ä½ çš„æŠ½å±‰/è¿æ¥å™¨åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®
object_center = np.array([0.0, 0.0, 0.0])  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
radius = 0.5  # ç›¸æœºè·ç‰©ä½“çš„è·ç¦»ï¼ˆç±³ï¼‰
```

### æ­¥éª¤ 2: ç”Ÿæˆç¯ç»•è½¨è¿¹

**ç»å…¸çš„åœ†å½¢è½¨è¿¹ï¼ˆæ°´å¹³ç¯ç»•ï¼‰ï¼š**

```python
import numpy as np

def generate_circular_trajectory(center, radius, num_views=50, height=0.0):
    """
    ç”Ÿæˆç¯ç»•ç‰©ä½“çš„åœ†å½¢ç›¸æœºè½¨è¿¹
    
    å‚æ•°ï¼š
        center: ç‰©ä½“ä¸­å¿ƒ [x, y, z]
        radius: è½¨è¿¹åŠå¾„
        num_views: è§†è§’æ•°é‡
        height: ç›¸æœºé«˜åº¦åç§»ï¼ˆç›¸å¯¹äºç‰©ä½“ä¸­å¿ƒï¼‰
    
    è¿”å›ï¼š
        poses: (num_views, 4, 4) çš„ç›¸æœº pose çŸ©é˜µ
    """
    poses = []
    
    for i in range(num_views):
        angle = 2 * np.pi * i / num_views
        
        # ç›¸æœºä½ç½®ï¼ˆåœ¨åœ†å‘¨ä¸Šï¼‰
        x = center[0] + radius * np.cos(angle)
        y = center[1] + height
        z = center[2] + radius * np.sin(angle)
        
        camera_pos = np.array([x, y, z])
        
        # ç›¸æœºæœå‘ä¸­å¿ƒ
        forward = center - camera_pos  # Z è½´ï¼ˆæœå‘ç‰©ä½“ï¼‰
        forward = forward / np.linalg.norm(forward)
        
        # ä¸Šæ–¹å‘ï¼ˆå›ºå®šä¸ºä¸–ç•Œåæ ‡ç³»çš„ +Yï¼‰
        up = np.array([0.0, 1.0, 0.0])
        
        # å³æ–¹å‘ï¼ˆX è½´ï¼‰
        right = np.cross(forward, up)
        right = right / np.linalg.norm(right)
        
        # é‡æ–°è®¡ç®—ä¸Šæ–¹å‘ï¼ˆç¡®ä¿æ­£äº¤ï¼‰
        up = np.cross(right, forward)
        up = up / np.linalg.norm(up)
        
        # æ„å»ºæ—‹è½¬çŸ©é˜µ
        # æ³¨æ„ï¼šNeRF çº¦å®š Z è½´æœå‰ï¼Œæ‰€ä»¥åˆ—çš„é¡ºåºæ˜¯ [right, up, -forward]
        R = np.stack([right, up, -forward], axis=1)
        
        # æ„å»º 4x4 å˜æ¢çŸ©é˜µ
        pose = np.eye(4)
        pose[:3, :3] = R
        pose[:3, 3] = camera_pos
        
        poses.append(pose)
    
    return np.array(poses)


# ä½¿ç”¨ç¤ºä¾‹
object_center = np.array([0.0, 0.0, 0.0])  # æ ¹æ®æ­¥éª¤1çš„ç»“æœè°ƒæ•´
radius = 0.5
num_views = 50

poses = generate_circular_trajectory(object_center, radius, num_views)
print(f"ç”Ÿæˆäº† {len(poses)} ä¸ªç›¸æœº pose")
```

**æ›´å¤æ‚çš„è½¨è¿¹ï¼ˆèºæ—‹ã€å¤šå±‚ç¯ç»•ï¼‰ï¼š**

```python
def generate_spiral_trajectory(center, radius, num_views=50, 
                               height_range=(-0.2, 0.2)):
    """èºæ—‹è½¨è¿¹ï¼šç›¸æœºé«˜åº¦é€æ¸å˜åŒ–"""
    poses = []
    
    for i in range(num_views):
        angle = 2 * np.pi * i / num_views
        
        # é«˜åº¦çº¿æ€§å˜åŒ–
        t = i / (num_views - 1)
        height = height_range[0] + t * (height_range[1] - height_range[0])
        
        x = center[0] + radius * np.cos(angle)
        y = center[1] + height
        z = center[2] + radius * np.sin(angle)
        
        camera_pos = np.array([x, y, z])
        
        # ... åŒä¸Šï¼Œæ„å»º pose
        
    return np.array(poses)


def generate_multilayer_trajectory(center, radius, num_views_per_layer=20,
                                   heights=[-0.2, 0.0, 0.2]):
    """å¤šå±‚ç¯ç»•ï¼šåœ¨ä¸åŒé«˜åº¦å„æ‹ä¸€åœˆ"""
    all_poses = []
    
    for height in heights:
        layer_poses = generate_circular_trajectory(
            center, radius, num_views_per_layer, height
        )
        all_poses.extend(layer_poses)
    
    return np.array(all_poses)
```

### æ­¥éª¤ 3: ä¿®æ”¹ render.py ä½¿ç”¨è‡ªå®šä¹‰è½¨è¿¹

åˆ›å»ºä¸€ä¸ªä¿®æ”¹ç‰ˆçš„ render è„šæœ¬ï¼š

```python
# custom_render.py

import torch
import numpy as np
from gaussian_splatting.utils.camera_utils import Camera

class CustomCamera:
    """è‡ªå®šä¹‰ç›¸æœºç±»ï¼Œç”¨äºæ¸²æŸ“"""
    def __init__(self, pose, width, height, fx, fy, cx, cy):
        """
        å‚æ•°ï¼š
            pose: 4x4 camera-to-world çŸ©é˜µ
            width, height: å›¾åƒå°ºå¯¸
            fx, fy: ç„¦è·
            cx, cy: ä¸»ç‚¹
        """
        self.pose = pose
        self.width = width
        self.height = height
        self.fx = fx
        self.fy = fy
        self.cx = cx
        self.cy = cy
        
        # è½¬æ¢ä¸º world-to-cameraï¼ˆGS æ¸²æŸ“éœ€è¦ï¼‰
        self.world_to_camera = np.linalg.inv(pose)
        
        # æ„å»ºæŠ•å½±çŸ©é˜µ
        self.setup_projection_matrix()
    
    def setup_projection_matrix(self):
        # æ„å»ºå†…å‚çŸ©é˜µ
        self.K = np.array([
            [self.fx, 0, self.cx],
            [0, self.fy, self.cy],
            [0, 0, 1]
        ])
        
        # ... å…¶ä»–å¿…è¦çš„ç›¸æœºå‚æ•°


def render_custom_trajectory(gs_model, poses, intrinsics, output_dir):
    """
    ä½¿ç”¨è‡ªå®šä¹‰è½¨è¿¹æ¸²æŸ“
    
    å‚æ•°ï¼š
        gs_model: åŠ è½½çš„ GS æ¨¡å‹
        poses: (N, 4, 4) ç›¸æœº pose æ•°ç»„
        intrinsics: ç›¸æœºå†…å‚ dict {fx, fy, cx, cy, width, height}
        output_dir: è¾“å‡ºç›®å½•
    """
    
    os.makedirs(output_dir, exist_ok=True)
    
    for idx, pose in enumerate(poses):
        # åˆ›å»ºè‡ªå®šä¹‰ç›¸æœº
        cam = CustomCamera(
            pose=pose,
            width=intrinsics['width'],
            height=intrinsics['height'],
            fx=intrinsics['fx'],
            fy=intrinsics['fy'],
            cx=intrinsics['cx'],
            cy=intrinsics['cy']
        )
        
        # æ¸²æŸ“
        render_pkg = render(cam, gs_model, pipeline, background)
        
        # ä¿å­˜
        rgb = render_pkg["render"]
        depth = render_pkg["depth_hand"]
        normal = render_pkg["gs_normal"]
        
        save_image(rgb, f"{output_dir}/rgb_{idx:04d}.png")
        save_image(depth, f"{output_dir}/depth_{idx:04d}.png")
        save_image(normal, f"{output_dir}/normal_{idx:04d}.png")
```

### æ­¥éª¤ 4: å®Œæ•´çš„æ¸²æŸ“æµç¨‹

```python
# main_custom_render.py

import numpy as np
import json
from pathlib import Path

# 1. åˆ†æè®­ç»ƒæ•°æ®ï¼Œç¡®å®šç‰©ä½“ä½ç½®
with open('transforms.json', 'r') as f:
    train_data = json.load(f)

camera_positions = []
for frame in train_data['frames']:
    T = np.array(frame['transform_matrix'])
    camera_positions.append(T[:3, 3])

object_center = np.mean(camera_positions, axis=0)
avg_radius = np.mean(np.linalg.norm(
    np.array(camera_positions) - object_center, axis=1
))

print(f"ç‰©ä½“ä¸­å¿ƒ: {object_center}")
print(f"å¹³å‡åŠå¾„: {avg_radius}")

# 2. ç”Ÿæˆç¯ç»•è½¨è¿¹
num_views = 100  # æ ¹æ®éœ€è¦è°ƒæ•´
poses = generate_circular_trajectory(
    center=object_center,
    radius=avg_radius * 0.8,  # ç¨å¾®è¿‘ä¸€ç‚¹
    num_views=num_views,
    height=0.0  # æˆ–è€…æ ¹æ®éœ€è¦è°ƒæ•´
)

# 3. è®¾ç½®ç›¸æœºå†…å‚ï¼ˆä»è®­ç»ƒæ•°æ®è·å–ï¼‰
if 'camera_angle_x' in train_data:
    # ä» FOV è®¡ç®—ç„¦è·
    fov_x = train_data['camera_angle_x']
    width = 800  # ä»è®­ç»ƒå›¾åƒè·å–
    height = 800
    fx = width / (2 * np.tan(fov_x / 2))
    fy = fx  # å‡è®¾æ­£æ–¹å½¢åƒç´ 
    cx = width / 2
    cy = height / 2
else:
    # æˆ–ä» fl_x, fl_y ç­‰å­—æ®µç›´æ¥è¯»å–
    fx = train_data['fl_x']
    fy = train_data['fl_y']
    cx = train_data['cx']
    cy = train_data['cy']
    width = train_data['w']
    height = train_data['h']

intrinsics = {
    'fx': fx, 'fy': fy,
    'cx': cx, 'cy': cy,
    'width': width, 'height': height
}

# 4. åŠ è½½ GS æ¨¡å‹å¹¶æ¸²æŸ“
from gaussian_splatting.scene import Scene
from gaussian_splatting.gaussian_renderer import GaussianModel

gaussians = GaussianModel(...)
scene = Scene(..., load_iteration=30000)

output_dir = Path("custom_renders")
render_custom_trajectory(gaussians, poses, intrinsics, output_dir)

# 5. ä¿å­˜ transforms.jsonï¼ˆSDF Studio æ ¼å¼ï¼‰
transforms_out = {
    "camera_angle_x": fov_x,
    "fl_x": fx,
    "fl_y": fy,
    "cx": cx,
    "cy": cy,
    "w": width,
    "h": height,
    "frames": []
}

for idx, pose in enumerate(poses):
    transforms_out['frames'].append({
        "file_path": f"./rgb/rgb_{idx:04d}.png",
        "depth_file_path": f"./depth/depth_{idx:04d}.png",
        "normal_file_path": f"./normal/normal_{idx:04d}.png",
        "transform_matrix": pose.tolist()
    })

with open(output_dir / "transforms.json", 'w') as f:
    json.dump(transforms_out, f, indent=2)

print(f"âœ“ å®Œæˆï¼æ¸²æŸ“äº† {num_views} ä¸ªè§†è§’")
```

### æ­¥éª¤ 5: è½¬æ¢ä¸º SDF Studio æ ¼å¼

SDF Studio é€šå¸¸éœ€è¦ä»¥ä¸‹æ•°æ®ç»“æ„ï¼š

```
data/
â”œâ”€â”€ rgb/
â”‚   â”œâ”€â”€ 0000.png
â”‚   â”œâ”€â”€ 0001.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ depth/  (å¯é€‰ï¼Œä½†å¾ˆæœ‰ç”¨)
â”‚   â”œâ”€â”€ 0000.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ normal/  (å¯é€‰)
â”‚   â”œâ”€â”€ 0000.png
â”‚   â””â”€â”€ ...
â””â”€â”€ transforms.json
```

`transforms.json` æ ¼å¼ï¼ˆä¸ NeRF å…¼å®¹ï¼‰ï¼š
```json
{
    "camera_angle_x": 0.8575,
    "fl_x": 1000.0,
    "fl_y": 1000.0,
    "cx": 400.0,
    "cy": 400.0,
    "w": 800,
    "h": 800,
    "frames": [
        {
            "file_path": "./rgb/0000.png",
            "depth_file_path": "./depth/0000.png",
            "transform_matrix": [[...]]
        }
    ]
}
```

## ğŸ“ å…³é”®æ¦‚å¿µæ€»ç»“

### Camera-to-World (C2W) çŸ©é˜µ

```
ç»™å®šç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹ P_camï¼Œè½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»ï¼š
P_world = C2W @ P_cam

C2W = [R | t]
      [0 | 1]

å…¶ä¸­ï¼š
- R: 3x3 æ—‹è½¬çŸ©é˜µï¼ˆç›¸æœºåæ ‡è½´åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„æ–¹å‘ï¼‰
- t: 3x1 å¹³ç§»å‘é‡ï¼ˆç›¸æœºåŸç‚¹åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä½ç½®ï¼‰
```

### ç›¸æœºæœå‘çš„æ„å»º

```python
# ç›¸æœºçœ‹å‘æŸä¸ªç‚¹ target
forward = normalize(target - camera_pos)  # Z è½´æ–¹å‘

# ä¸–ç•Œä¸Šæ–¹å‘
world_up = [0, 1, 0]

# å³æ–¹å‘ï¼ˆX è½´ï¼‰
right = normalize(cross(forward, world_up))

# çœŸå®ä¸Šæ–¹å‘ï¼ˆY è½´ï¼‰
up = normalize(cross(right, forward))

# æ³¨æ„ï¼šNeRF çº¦å®šæ˜¯ Z è½´æœå‰ï¼Œæ‰€ä»¥å®é™…æ„å»ºæ—¶ï¼š
R = [right, up, -forward]  # åˆ—å‘é‡
```

### åæ ‡ç³»ä¸€è‡´æ€§

**å…³é”®ç‚¹ï¼š**
- GS è®­ç»ƒæ—¶ç”¨çš„åæ ‡ç³» = ä½ ç°åœ¨æ¸²æŸ“æ—¶ç”¨çš„åæ ‡ç³»
- ç¡®ä¿ `neuralangelo_center` å’Œ `neuralangelo_scale` å‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´
- è‡ªå®šä¹‰è½¨è¿¹çš„ pose å¿…é¡»åœ¨åŒä¸€ä¸ªä¸–ç•Œåæ ‡ç³»ä¸‹

## ğŸ› ï¸ å®ç”¨å·¥å…·å‡½æ•°

```python
def look_at(camera_pos, target, up=np.array([0, 1, 0])):
    """
    æ„å»º look-at ç›¸æœºçŸ©é˜µ
    
    å‚æ•°ï¼š
        camera_pos: ç›¸æœºä½ç½® (3,)
        target: çœ‹å‘çš„ç›®æ ‡ç‚¹ (3,)
        up: ä¸–ç•Œä¸Šæ–¹å‘ (3,)
    
    è¿”å›ï¼š
        pose: 4x4 camera-to-world çŸ©é˜µ
    """
    forward = target - camera_pos
    forward = forward / np.linalg.norm(forward)
    
    right = np.cross(forward, up)
    right = right / np.linalg.norm(right)
    
    up_actual = np.cross(right, forward)
    up_actual = up_actual / np.linalg.norm(up_actual)
    
    # NeRF åæ ‡ç³»çº¦å®š
    R = np.column_stack([right, up_actual, -forward])
    
    pose = np.eye(4)
    pose[:3, :3] = R
    pose[:3, 3] = camera_pos
    
    return pose


def visualize_camera_trajectory(poses, object_center=None):
    """å¯è§†åŒ–ç›¸æœºè½¨è¿¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection='3d')
    
    # ç»˜åˆ¶ç›¸æœºä½ç½®
    camera_positions = poses[:, :3, 3]
    ax.plot(camera_positions[:, 0], 
            camera_positions[:, 1], 
            camera_positions[:, 2], 
            'b-', label='Camera Path')
    ax.scatter(camera_positions[:, 0], 
               camera_positions[:, 1], 
               camera_positions[:, 2], 
               c='blue', marker='o')
    
    # ç»˜åˆ¶ç›¸æœºæœå‘
    for i, pose in enumerate(poses[::5]):  # æ¯5ä¸ªç”»ä¸€ä¸ª
        pos = pose[:3, 3]
        forward = -pose[:3, 2] * 0.1  # Z è½´æ–¹å‘
        ax.quiver(pos[0], pos[1], pos[2],
                 forward[0], forward[1], forward[2],
                 color='red', arrow_length_ratio=0.3)
    
    # ç»˜åˆ¶ç‰©ä½“ä¸­å¿ƒ
    if object_center is not None:
        ax.scatter(*object_center, c='green', marker='*', 
                  s=200, label='Object Center')
    
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    ax.legend()
    ax.set_title('Camera Trajectory')
    
    plt.show()
```

## ğŸ“ å®Œæ•´å·¥ä½œæµæ€»ç»“

```
1. è®­ç»ƒ GS æ¨¡å‹ï¼ˆä½ å·²ç»å®Œæˆï¼‰
   â†“
2. åˆ†æè®­ç»ƒæ•°æ®ï¼Œç¡®å®šç‰©ä½“ä¸­å¿ƒå’Œåˆé€‚çš„ç›¸æœºè·ç¦»
   â†“
3. ç”Ÿæˆç¯ç»•ç‰©ä½“çš„è‡ªå®šä¹‰ç›¸æœºè½¨è¿¹
   â†“
4. ä¿®æ”¹ render.py ä»¥æ”¯æŒè‡ªå®šä¹‰ç›¸æœº
   â†“
5. æ¸²æŸ“ RGB + Depth + Normal
   â†“
6. ä¿å­˜ä¸º SDF Studio æ ¼å¼
   â†“
7. ç”¨ SDF Studio è®­ç»ƒ Neural Surface
```

## ğŸš¨ å¸¸è§é—®é¢˜

### Q1: æ¸²æŸ“å‡ºæ¥çš„å›¾åƒä¸å¯¹ï¼Ÿ
- æ£€æŸ¥åæ ‡ç³»æ˜¯å¦ä¸€è‡´
- ç¡®è®¤ `neuralangelo_center` å’Œ `neuralangelo_scale` å‚æ•°
- å¯è§†åŒ–ç›¸æœºè½¨è¿¹

### Q2: æ·±åº¦å›¾å°ºåº¦ä¸å¯¹ï¼Ÿ
- GS çš„æ·±åº¦æ˜¯ç›¸å¯¹äºç›¸æœºçš„è·ç¦»
- ç¡®ä¿ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•°

### Q3: å¦‚ä½•ç¡®å®šåˆé€‚çš„ç›¸æœºè·ç¦»ï¼Ÿ
- ä»è®­ç»ƒæ•°æ®åˆ†æå¹³å‡è·ç¦»
- ç¡®ä¿ç‰©ä½“åœ¨å›¾åƒä¸­å æ®åˆé€‚çš„å¤§å°ï¼ˆ30-70% ç”»é¢ï¼‰

---

å¸Œæœ›è¿™ä¸ªè¯¦ç»†çš„è§£é‡Šèƒ½å¸®åˆ°ä½ ï¼å¦‚æœæœ‰å…·ä½“çš„ä»£ç å®ç°éœ€æ±‚ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†™å®Œæ•´çš„è„šæœ¬ã€‚